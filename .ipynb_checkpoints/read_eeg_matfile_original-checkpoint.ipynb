{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.linalg import eig\n",
    "import matplotlib.pyplot as plt\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\BCI_MINI\\recordings\n"
     ]
    }
   ],
   "source": [
    "cd \"D:/BCI_MINI/recordings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_eeg_mat(filename, centered=True):\n",
    "    all_data = io.loadmat(filename)\n",
    "    eeg_data = all_data['data_cur']\n",
    "    if centered:\n",
    "        eeg_data = eeg_data - np.mean(eeg_data,1)[np.newaxis].T\n",
    "        print 'Data were centered: channels are zero-mean'\n",
    "    states_labels = all_data['states_cur']\n",
    "    states_codes = list(np.unique(states_labels)[:])\n",
    "    sampling_rate = all_data['srate']\n",
    "    chan_names = all_data['chan_names']\n",
    "    return eeg_data, states_labels, sampling_rate, chan_names, eeg_data.shape[0], eeg_data.shape[1], states_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, sampling_rate, order=5):\n",
    "    nyq_freq = sampling_rate*0.5\n",
    "    low = lowcut/nyq_freq\n",
    "    high = highcut/nyq_freq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_high_low_pass(lowcut, highcut, sampling_rate, order=5):\n",
    "    nyq_freq = sampling_rate*0.5\n",
    "    lower_bound = lowcut/nyq_freq\n",
    "    higher_bound = highcut/nyq_freq\n",
    "    b_high, a_high = butter(order, lower_bound, btype='high')\n",
    "    b_low, a_low = butter(order, higher_bound, btype='low')\n",
    "    return b_high, a_high, b_low, a_low\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, sampling_rate, order=5, how_to_filt = 'separately'):\n",
    "    if how_to_filt == 'separately':\n",
    "        b_high, a_high, b_low, a_low = butter_high_low_pass(lowcut, highcut, sampling_rate, order=order)\n",
    "        y = lfilter(b_high, a_high, data)\n",
    "        y = lfilter(b_low, a_low, y)\n",
    "    elif how_to_filt == 'simultaneously':\n",
    "        b, a = butter_bandpass(lowcut, highcut, sampling_rate, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_outliers(data_raw, states_labels_raw, iter_numb):\n",
    "    data = np.copy(data_raw)\n",
    "    states_labels = np.copy(states_labels_raw)\n",
    "    data_pwr = np.sqrt(np.sum(data**2,0))\n",
    "    \n",
    "    for i in range(iter_numb):\n",
    "        X_mean = np.mean(data_pwr)\n",
    "        X_std = np.std(data_pwr)\n",
    "        mask = np.abs(data_pwr - X_mean) < 2.5*np.abs(X_std)\n",
    "        data = data[:, mask]\n",
    "        states_labels = states_labels[:, mask]\n",
    "        data_pwr = data_pwr[mask]\n",
    "        print 'Samples left after outliers removal:', data_pwr.shape[0]\n",
    "        \n",
    "    return data, states_labels\n",
    "\n",
    "\n",
    "def remove_eog_simple(data, chan_names, eyechan, N_art_comp=3):\n",
    "    \n",
    "    only_eye_chan = data[chan_names[0,:]==eyechan,:]\n",
    "    exceed_mask = only_eye_chan > 3*np.mean(np.absolute(only_eye_chan))\n",
    "    print 'Number of samples identified as containing eye artifacts:', np.sum(exceed_mask)\n",
    "    U, S, V = np.linalg.svd(data[:, exceed_mask[0,:]], full_matrices=True)\n",
    "    M_eog = np.eye(U.shape[0])-np.dot(U[:,0:N_art_comp],U[:,0:N_art_comp].T)\n",
    "    \n",
    "    return np.dot(M_eog,data), M_eog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outer_n(n):\n",
    "    return np.array(list(range(n))+list(range(-n,0)))\n",
    "\n",
    "def whitener(C, rtol=1e-15):\n",
    "    e, E = np.linalg.eigh(C)\n",
    "    return reduce(np.dot, [E, np.diag(np.where(e > np.max(e) * rtol, e, np.inf)**-0.5), E.T])\n",
    "\n",
    "def csp_base(C_a, C_b):\n",
    "    P = whitener(C_a + C_b)\n",
    "    P_C_b = reduce(np.dot, [P, C_b, P.T])\n",
    "    _, _, B = np.linalg.svd((P_C_b))\n",
    "    return np.dot(B, P.T)\n",
    "\n",
    "def csp(C_a, C_b, m):\n",
    "    W = csp_base(C_a, C_b)\n",
    "    assert W.shape[1] >= 2*m\n",
    "    return W[outer_n(m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_CSP_matr(data, states_labels, main_state, N_comp, other_state=None, mode='one_vs_all'):\n",
    "    \n",
    "    A = data[:, (states_labels == main_state)[0,:]]\n",
    "    if mode == 'one_vs_all':\n",
    "        B = data[:, (states_labels != main_state)[0,:]]\n",
    "    elif mode == 'pairwise':\n",
    "        if other_state == None:\n",
    "            print \"Other state must be specified\"\n",
    "            return None\n",
    "        else:\n",
    "            B = data[:, (states_labels == other_state)[0,:]]\n",
    "    \n",
    "    #C1 = np.dot(A,A.T)/float(A.shape[1])\n",
    "    #C2 = np.dot(B,B.T)/float(B.shape[1])\n",
    "    C1 = np.cov(A)\n",
    "    C2 = np.cov(B)\n",
    "    \n",
    "    return csp(C1,C2,N_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def const_features(data,states_labels,states_codes,sr,feat_type,freq_ranges,how_to_filt,N_csp_comp,win,order=5,normalize=False):\n",
    "    '''\n",
    "    Filters data according to specified bands (in freq_range) and derives CSP transformations for each band.\n",
    "    Type of CSP should be provided in feat_type: pairwise or one-vs-all (recommended).\n",
    "    Number of CSP components should be provided in N_csp_comp (for a given N, N first and N last components will be used).\n",
    "    Time interval for averaging is specified in win.\n",
    "    If normalize=True, each data point is in [0,1].\n",
    "    Returns array of transformed data, list of CSP transform matrices (in arrays), \n",
    "    and array of state codes for each of the final features (i.e., which state was first while this CSP projection was computed)\n",
    "    '''\n",
    "    final_data = np.zeros((1, data.shape[1]))\n",
    "    all_CSPs = []\n",
    "    if feat_type == 'CSP_pairwise':\n",
    "        where_states = []\n",
    "        for freq in freq_ranges:\n",
    "            data_filt = butter_bandpass_filter(data, freq[0], freq[1], sr, order, how_to_filt)\n",
    "            all_states_CSP = []\n",
    "            for st in states_codes:\n",
    "                for oth_st in np.array(states_codes)[np.array(states_codes)!=st]:\n",
    "                    CSP_st = get_CSP_matr(data_filt, states_labels, st, N_csp_comp, other_state=oth_st, mode='pairwise')\n",
    "                    all_states_CSP.append(np.dot(CSP_st, data_filt))\n",
    "                    all_CSPs.append(CSP_st)\n",
    "                    where_states.extend([st]*(N_csp_comp*2))\n",
    "                data_transformed = np.vstack(all_states_CSP)**2\n",
    "            final_data = np.vstack((final_data, data_transformed))\n",
    "            \n",
    "    elif feat_type == 'CSP_one_vs_all':\n",
    "        where_states = []\n",
    "        for freq in freq_ranges:\n",
    "            data_filt = butter_bandpass_filter(data, freq[0], freq[1], sr, order, how_to_filt)\n",
    "            all_states_CSP = []\n",
    "            for st in states_codes:\n",
    "                CSP_st = get_CSP_matr(data_filt, states_labels, st, N_csp_comp, other_state=None, mode='one_vs_all')\n",
    "                all_states_CSP.append(np.dot(CSP_st, data_filt))\n",
    "                all_CSPs.append(CSP_st)\n",
    "                where_states.extend([st]*(N_csp_comp*2))\n",
    "            data_transformed = np.vstack(all_states_CSP)**2\n",
    "            final_data = np.vstack((final_data, data_transformed))\n",
    "\n",
    "    final_data = final_data[1:,:]\n",
    "    a_ma = 1\n",
    "    b_ma = np.ones(win)/float(win)\n",
    "    final_data = lfilter(b_ma, a_ma, final_data)\n",
    "    if normalize:\n",
    "        final_data = final_data/np.sum(final_data,0)[np.newaxis,:]\n",
    "    print 'Shape of data matrix:', final_data.shape\n",
    "        \n",
    "    return final_data, all_CSPs, np.array(where_states)\n",
    "\n",
    "def filt_apply_CSPs(data, sr, freq_range, all_CSPs, how_to_filt, win, order=5, normalize=False):\n",
    "    '''\n",
    "    Filters data according to specified bands (in freq_range) and applies corresponding CSP transformations (in all_CSPs).\n",
    "    Order in freq_range and all_CSPs must be the same.\n",
    "    If normalize=True, each data point is in [0,1].\n",
    "    '''\n",
    "    N_csp_per_freq = len(all_CSPs)/len(freq_range)\n",
    "    all_CSPs_copy = list(all_CSPs)\n",
    "    transformed_data = np.zeros((1, data.shape[1]))\n",
    "    for fr_ind in range(len(freq_range)):\n",
    "        filt_data = butter_bandpass_filter(data,freq_range[fr_ind][0],freq_range[fr_ind][1],sr,order,how_to_filt)\n",
    "        for csp_ind in range(N_csp_per_freq):\n",
    "            transformed_data = np.vstack((transformed_data, np.dot(all_CSPs_copy.pop(0), filt_data)))\n",
    "    final_data = transformed_data[1:,:]**2\n",
    "    a_ma = 1\n",
    "    b_ma = np.ones(win)/float(win)\n",
    "    final_data = lfilter(b_ma, a_ma, final_data)\n",
    "    if normalize:\n",
    "        final_data = final_data/np.sum(final_data,0)[np.newaxis,:]\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load all data\n",
    "filename = 'sm_ksenia_1'\n",
    "[eeg_data, states_labels, sampling_rate, chan_names, chan_numb, samp_numb, states_codes] = open_eeg_mat(filename, centered=False)\n",
    "sampling_rate = sampling_rate[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prefilter eeg data\n",
    "eeg_data = butter_bandpass_filter(eeg_data, 0.5, 45, sampling_rate, order=5, how_to_filt = 'separately')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples left after outliers removal: 54809\n",
      "Samples left after outliers removal: 54179\n",
      "Samples left after outliers removal: 52623\n",
      "Samples left after outliers removal: 51129\n",
      "Samples left after outliers removal: 49954\n",
      "Samples left after outliers removal: 49212\n",
      "Samples left after outliers removal: 48762\n",
      "Number of samples identified as containing eye artifacts: 390\n"
     ]
    }
   ],
   "source": [
    "# Remove empty channels\n",
    "nozeros_mask = np.sum(eeg_data[:,:sampling_rate*2],1)!=0 # Detect constant (zero) channels\n",
    "without_emp_mask = nozeros_mask & (chan_names[0,:]!='A1') & (chan_names[0,:]!='A2') & (chan_names[0,:]!='AUX')\n",
    "eeg_data = eeg_data[without_emp_mask,:] # Remove constant (zero) channels and prespecified channels\n",
    "chan_names_used = chan_names[:,without_emp_mask]\n",
    "\n",
    "# Remove outliers; remove artifacts (blinks, eye movements)\n",
    "eeg_data, states_labels = remove_outliers(eeg_data, states_labels, 7)\n",
    "eeg_data, M_eog = remove_eog_simple(eeg_data,chan_names_used,'Fp1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data matrix: (90, 48762)\n"
     ]
    }
   ],
   "source": [
    "# Construct features: project eeg data on CSP components (separately for each of specified frequency bands)\n",
    "N_CSP_comp = 1 # N first and N last; 2*N in total\n",
    "win = sampling_rate/2 # Window for averaging: 0.5 sec\n",
    "frequences = [(6,10),(8,12),(10,14),(12,16),(14,18),(16,20),(18,22),(20,24),\n",
    "              (22,26),(24,28),(26,30),(28,32),(30,34),(32,36),(34,38)]\n",
    "eeg_data, all_CSPs, where_states = const_features(eeg_data,states_labels,states_codes,sampling_rate,'CSP_one_vs_all',\n",
    "                                                    frequences,'separately',N_CSP_comp,win,normalize=False)\n",
    "\n",
    "eeg_data = eeg_data[:, win*2:]\n",
    "states_labels = states_labels[:, win*2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 vs all:\n",
      "Frequency band (14, 18) provided CSP components: [1]\n",
      "Frequency band (16, 20) provided CSP components: [1]\n",
      "\n",
      "2 vs all:\n",
      "Frequency band (6, 10) provided CSP components: [1]\n",
      "Frequency band (14, 18) provided CSP components: [1]\n",
      "Frequency band (16, 20) provided CSP components: [1]\n",
      "\n",
      "6 vs all:\n",
      "Frequency band (6, 10) provided CSP components: [1]\n",
      "Frequency band (10, 14) provided CSP components: [1]\n",
      "Frequency band (26, 30) provided CSP components: [1]\n",
      "\n",
      "Irrelevant features have been removed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression #Lasso\n",
    "\n",
    "tuned_parameters = [{'C': [0.0005]}]\n",
    "\n",
    "clf_l1_LR_1vsAll = GridSearchCV(LogisticRegression(penalty='l1'), tuned_parameters, cv=3)\n",
    "clf_l1_LR_2vsAll = GridSearchCV(LogisticRegression(penalty='l1'), tuned_parameters, cv=3)\n",
    "clf_l1_LR_6vsAll = GridSearchCV(LogisticRegression(penalty='l1'), tuned_parameters, cv=3)\n",
    "#clf_l1_LR_1vsAll = LogisticRegression(C=0.001, penalty='l1')#Lasso(alpha=0.01)\n",
    "#clf_l1_LR_2vsAll = LogisticRegression(C=0.001, penalty='l1')#Lasso(alpha=0.01)\n",
    "#clf_l1_LR_6vsAll = LogisticRegression(C=0.001, penalty='l1')#Lasso(alpha=0.01)\n",
    "\n",
    "\n",
    "data_state_1 = eeg_data[(where_states==1), :]\n",
    "data_state_1 = data_state_1[:, (states_labels == 1)[0,:]]\n",
    "data_states_NOT_1 = eeg_data[(where_states==1), :]\n",
    "data_states_NOT_1 = data_states_NOT_1[:, (states_labels != 1)[0,:]]\n",
    "clf_l1_LR_1vsAll.fit(np.hstack((data_state_1, data_states_NOT_1)).T, \n",
    "                     np.vstack((np.ones((data_state_1.shape[1],1)),np.zeros((data_states_NOT_1.shape[1],1)))).ravel())\n",
    "\n",
    "data_state_2 = eeg_data[(where_states==2), :]\n",
    "data_state_2 = data_state_2[:, (states_labels == 2)[0,:]]\n",
    "data_states_NOT_2 = eeg_data[(where_states==2), :]\n",
    "data_states_NOT_2 = data_states_NOT_2[:, (states_labels != 2)[0,:]]\n",
    "clf_l1_LR_2vsAll.fit(np.hstack((data_state_2, data_states_NOT_2)).T, \n",
    "                    np.vstack((np.ones((data_state_2.shape[1],1)),np.zeros((data_states_NOT_2.shape[1],1)))).ravel())\n",
    "\n",
    "data_state_6 = eeg_data[(where_states==6), :]\n",
    "data_state_6 = data_state_6[:, (states_labels == 6)[0,:]]\n",
    "data_states_NOT_6 = eeg_data[(where_states==6), :]\n",
    "data_states_NOT_6 = data_states_NOT_6[:, (states_labels != 6)[0,:]]\n",
    "clf_l1_LR_6vsAll.fit(np.hstack((data_state_6, data_states_NOT_6)).T, \n",
    "                    np.vstack((np.ones((data_state_6.shape[1],1)),np.zeros((data_states_NOT_6.shape[1],1)))).ravel())\n",
    "\n",
    "all_coef_lasso = [clf_l1_LR_1vsAll.best_estimator_.coef_, clf_l1_LR_2vsAll.best_estimator_.coef_, \n",
    "                  clf_l1_LR_6vsAll.best_estimator_.coef_]\n",
    "for ind_coef_matr in range(len(all_coef_lasso)):\n",
    "    dummy_matr = all_coef_lasso[ind_coef_matr].reshape((len(frequences),N_CSP_comp*2))\n",
    "    print '\\n',states_codes[ind_coef_matr],'vs all:'\n",
    "    for i in range(len(frequences)):\n",
    "        if np.count_nonzero(dummy_matr[i,:])!=0:\n",
    "            print 'Frequency band', frequences[i], 'provided CSP components:', np.nonzero(dummy_matr[i,:])[0]+1\n",
    "            \n",
    "\n",
    "# Remove irrelevant (according to lasso LR) features \n",
    "masks_1 = np.split((clf_l1_LR_1vsAll.best_estimator_.coef_!=0), len(frequences), axis=1)\n",
    "masks_2 = np.split((clf_l1_LR_2vsAll.best_estimator_.coef_!=0), len(frequences), axis=1)\n",
    "masks_6 = np.split((clf_l1_LR_6vsAll.best_estimator_.coef_!=0), len(frequences), axis=1)\n",
    "masks_all_ordered = []\n",
    "for i in range(len(frequences)):\n",
    "    masks_all_ordered.extend(masks_1[i])\n",
    "    masks_all_ordered.extend(masks_2[i])\n",
    "    masks_all_ordered.extend(masks_6[i])\n",
    "    \n",
    "for j in range(len(masks_all_ordered)):\n",
    "    all_CSPs[j] = all_CSPs[j][masks_all_ordered[j],:]\n",
    "\n",
    "mask_data = np.hstack(masks_all_ordered)\n",
    "\n",
    "eeg_data = eeg_data[mask_data,:]\n",
    "print '\\nIrrelevant features have been removed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#examples_numb = eeg_data.shape[1]\n",
    "#mask_train = np.random.choice(np.arange(0,examples_numb), size=examples_numb/5, replace=False)\n",
    "#print eeg_data.shape, states_labels.shape\n",
    "#print 'State 1:', np.sum(states_labels==1)\n",
    "#print 'State 2:', np.sum(states_labels==2)\n",
    "#print 'State 6:', np.sum(states_labels==6)\n",
    "#eeg_data = eeg_data[:,mask_train]\n",
    "#states_labels = states_labels[:,mask_train]\n",
    "#print eeg_data.shape, states_labels.shape\n",
    "#print 'State 1:', np.sum(states_labels==1)\n",
    "#print 'State 2:', np.sum(states_labels==2)\n",
    "#print 'State 6:', np.sum(states_labels==6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class params:\n",
    "    def __init__(self):\n",
    "        self.srate = 0;\n",
    "        self.win_av = 0;\n",
    "        \n",
    "        self.without_emp_mask = 0;\n",
    "        \n",
    "        self.pre_fl = 0;\n",
    "        self.pre_fh = 0;\n",
    "        \n",
    "        self.filt_order = 0;\n",
    "        \n",
    "        self.M_eog = 0;\n",
    "        self.all_CSPs = 0\n",
    "        self.freqs = 0\n",
    "        \n",
    "        self.W1_saved = 0;\n",
    "        self.b1_saved = 0;\n",
    "        self.W2_saved = 0;\n",
    "        self.b2_saved = 0;\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_0 = params();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_0.all_CSPs = all_CSPs;\n",
    "params_0.freqs = frequences;\n",
    "params_0.win_av = win;\n",
    "params_0.srate = sampling_rate;\n",
    "params_0.filt_order = 5;\n",
    "params_0.pre_fl = 45;\n",
    "params_0.pre_fh = 0.5;\n",
    "\n",
    "params_0.M_eog = M_eog;\n",
    "\n",
    "params_0.without_emp_mask = without_emp_mask;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('params_0.pkl', 'rb') as input:\n",
    "        params_1 = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((63088, 8), (63088, 1), (63088, 3))\n",
      "Input dim: 8 \n",
      "Hidden dim: 15 \n",
      "Output dim: 3\n"
     ]
    }
   ],
   "source": [
    "# ____________________Prepare data for NN training____________________\n",
    "\n",
    "examples_numb = eeg_data.shape[1]\n",
    "train_labels = np.copy(states_labels)\n",
    "train_labels[train_labels==1] = 0\n",
    "train_labels[train_labels==2] = 1\n",
    "train_labels[train_labels==6] = 2\n",
    "\n",
    "pre_labels_mask = np.zeros((3, examples_numb))\n",
    "for row in range(3):\n",
    "     pre_labels_mask[row, :] = row\n",
    "one_of_K_labeled = np.zeros((3, examples_numb))\n",
    "for row in range(3):\n",
    "    one_of_K_labeled[row, :] = (pre_labels_mask[row, :] == train_labels)\n",
    "\n",
    "# Examples in rows, features in columns\n",
    "train_data = eeg_data.T\n",
    "train_labels = train_labels.T\n",
    "one_of_K_labeled = one_of_K_labeled.T\n",
    "print (train_data.shape,train_labels.shape,one_of_K_labeled.shape)\n",
    "\n",
    "input_size = train_data.shape[1]\n",
    "hidd_size = 15 # Number of units in hidden layer\n",
    "out_size = one_of_K_labeled.shape[1]\n",
    "print 'Input dim:', int(input_size), '\\nHidden dim:', hidd_size, '\\nOutput dim:', int(out_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ____________________Set NN____________________\n",
    "\n",
    "X = theano.tensor.fmatrix('X')\n",
    "Y = theano.tensor.imatrix('Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Randomly initialize weights and biases\n",
    "W1_init = np.random.random((input_size,hidd_size)).astype('float32')*0.1\n",
    "b1_init = np.random.random((hidd_size)).astype('float32')*0.1\n",
    "W2_init = np.random.random((hidd_size,out_size)).astype('float32')*0.1\n",
    "b2_init = np.random.random((out_size)).astype('float32')*0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "W1 = theano.shared(W1_init, name = 'W1')\n",
    "b1 = theano.shared(b1_init, name = 'b1')\n",
    "W2 = theano.shared(W2_init, name = 'W2')\n",
    "b2 = theano.shared(b2_init, name = 'b2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dot_1 = theano.tensor.dot(X, W1) + b1\n",
    "activ_1 = theano.tensor.nnet.sigmoid(dot_1)\n",
    "dot_2 = theano.tensor.dot(activ_1, W2) + b2\n",
    "activ_final = theano.tensor.nnet.softmax(dot_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_0.W1_saved = W1.get_value();\n",
    "params_0.b1_saved = b1.get_value();\n",
    "params_0.W2_saved = W2.get_value();\n",
    "params_0.b2_saved = b2.get_value();\n",
    "\n",
    "save_object(params_0, 'params_0.pkl');\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get the index of an output with the max activation (probability)\n",
    "pred_y = theano.tensor.argmax(activ_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define loss function\n",
    "cross_loss = theano.tensor.nnet.categorical_crossentropy(activ_final, Y).mean() # Average cross-entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Automatically find expressions for gradients\n",
    "g_W2 = theano.tensor.grad(cross_loss, W2)\n",
    "g_b2 = theano.tensor.grad(cross_loss, b2)\n",
    "g_W1 = theano.tensor.grad(cross_loss, W1)\n",
    "g_b1 = theano.tensor.grad(cross_loss, b1)\n",
    "\n",
    "# Set learning rates for weights and biases\n",
    "lr_W1 = np.array(0.09).astype('float32')\n",
    "lr_b1 = np.array(0.09).astype('float32')\n",
    "lr_W2 = np.array(0.01).astype('float32')\n",
    "lr_b2 = np.array(0.01).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define how to update weights and biases\n",
    "updates_for_params = [(W2, W2 - lr_W2*g_W2),\n",
    "                      (b2, b2 - lr_b2*g_b2),\n",
    "                      (W1, W1 - lr_W1*g_W1),\n",
    "                      (b1, b1 - lr_b1*g_b1)]\n",
    "\n",
    "# Define theano function that trains network\n",
    "train_net = theano.function(inputs = [X, Y],\n",
    "                           outputs = cross_loss,\n",
    "                           updates = updates_for_params,\n",
    "                           allow_input_downcast = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to get classes' probabilities for a given input\n",
    "pred_proba = theano.function([X], activ_final, allow_input_downcast = True)\n",
    "\n",
    "# Function to predict class for a given input\n",
    "predict_val = theano.function([X], pred_y, allow_input_downcast = True)\n",
    "\n",
    "# Function to check accuracy on a dataset (proportion of correct)\n",
    "def accuracy_for_dataset(inputs, labels):\n",
    "    return sum([predict_val(inputs[i,:].reshape(1,inputs.shape[1])) == labels[i] \n",
    "                for i in range(inputs.shape[0])])/float(inputs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63088, 8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = train_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = [predict_val(inputs[i,:].reshape(1,inputs.shape[1])) for i in range(inputs.shape[0])];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_np = np.array(test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.uint8"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ____________________NN TRAINING____________________\n",
    "\n",
    "batch_size = 10\n",
    "iter_numb = train_data.shape[0]//batch_size\n",
    "max_epoch = 15\n",
    "all_mean_loss = []\n",
    "\n",
    "for epoch_ in xrange(max_epoch):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    loss_list = []\n",
    "    for iter_ in np.random.choice(np.arange(0,examples_numb), size=(iter_numb), replace=False):\n",
    "        loss_list.append(train_net(train_data[iter_:iter_+batch_size,:], one_of_K_labeled[iter_:iter_+batch_size,:]))\n",
    "    \n",
    "    mean_loss = np.mean(loss_list)\n",
    "    \n",
    "    print 'Time passed (min):', (time.time()-start_time)/float(60)\n",
    "    #if not epoch_ % 10:\n",
    "    print 'Epoch '+str(epoch_)+':\\naverage loss is '+str(mean_loss)+'\\n'\n",
    "\n",
    "    all_mean_loss.append(mean_loss)\n",
    "    if epoch_>0 and (all_mean_loss[-2]-all_mean_loss[-1])>0.0 and (all_mean_loss[-2]-all_mean_loss[-1])<0.0001:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: [ 0.32456252]\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy on training dataset\n",
    "print 'Train accuracy:', accuracy_for_dataset(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63088, 8)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63088, 1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sr = np.array([[sampling_rate]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[250]], dtype=uint8)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ____________________Test classifier on new data____________________\n",
    "\n",
    "filename_test = 'ks_1'\n",
    "\n",
    "[eeg_data_test,states_labels_test,sampling_rate_test,chan_names_test,chan_numb_test,samp_numb_test,states_codes_test] = open_eeg_mat(filename_test,\n",
    "                                                                                                                                     centered=False)\n",
    "\n",
    "eeg_data_test = butter_bandpass_filter(eeg_data_test, 0.5, 45, sampling_rate_test, order=5, how_to_filt='separately')\n",
    "eeg_data_test = eeg_data_test[without_emp_mask,:]\n",
    "chan_names_test_used = chan_names_test[:,without_emp_mask]\n",
    "eeg_data_test = np.dot(M_eog,eeg_data_test)\n",
    "\n",
    "eeg_data_test = filt_apply_CSPs(eeg_data_test, sampling_rate_test, frequences, all_CSPs, 'separately', win, normalize=False)\n",
    "\n",
    "\n",
    "test_data = eeg_data_test.T\n",
    "\n",
    "test_labels = np.copy(states_labels_test)\n",
    "test_labels[test_labels==1] = 0\n",
    "test_labels[test_labels==2] = 1\n",
    "test_labels[test_labels==6] = 2\n",
    "test_labels = test_labels.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[250]], dtype=uint8)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_rate_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: [ 0.33390226]\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy on test dataset\n",
    "print 'Test accuracy:', accuracy_for_dataset(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "filename_test = 'ks_1'\n",
    "\n",
    "[eeg_data_test,states_labels_test,sampling_rate_test,chan_names_test,chan_numb_test,samp_numb_test,states_codes_test] = open_eeg_mat(filename_test,\n",
    "                                                                                                                                     centered=False)\n",
    "\n",
    "eeg_data_test = butter_bandpass_filter(eeg_data_test, 0.5, 45, sampling_rate_test, order=5, how_to_filt='separately')\n",
    "eeg_data_test = eeg_data_test[without_emp_mask,:]\n",
    "chan_names_test_used = chan_names_test[:,without_emp_mask]\n",
    "eeg_data_test = np.dot(M_eog,eeg_data_test)\n",
    "\n",
    "eeg_data_test = filt_apply_CSPs(eeg_data_test, sampling_rate_test, frequences, all_CSPs, 'separately', win, normalize=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 73237)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_nonzero = 0;\n",
    "\n",
    "num_all = len(all_CSPs);\n",
    "for i in range(num_all):\n",
    "    if(all_CSPs[i].shape[0] > 0):\n",
    "        num_nonzero = num_nonzero + 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
